{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Exercise of Financial Crises Prediction Using Machine Learning Techniques\n",
    "## Inspired by Bluwstein et al. (2019)\n",
    "# Authors:                Ana Margarida Silva da Costa & Lea Katharina Paoli\n",
    "# Matriculation Nr.      Q00087 & E12499\n",
    "# Purpose:               Assignment for Advanced Financial Economics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\magui\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas-datareader in c:\\users\\magui\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.23 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas-datareader) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: lxml in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas-datareader) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\magui\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.6 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\magui\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\magui\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: jdcal in c:\\users\\magui\\anaconda3\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\magui\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\magui\\anaconda3\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\magui\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\magui\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to check whether the installation worked properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- -------------------\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.7.2\n",
      "anaconda-navigator                 2.0.3\n",
      "anaconda-project                   0.8.3\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.4.2\n",
      "astropy                            4.0.2\n",
      "async-generator                    1.10\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              20.3.0\n",
      "autopep8                           1.5.4\n",
      "Babel                              2.8.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.1\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.9.3\n",
      "bitarray                           1.6.1\n",
      "bkcharts                           0.2\n",
      "bleach                             3.2.1\n",
      "bokeh                              2.2.3\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "certifi                            2020.6.20\n",
      "cffi                               1.14.3\n",
      "chardet                            3.0.4\n",
      "click                              7.1.2\n",
      "cloudpickle                        1.6.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "comtypes                           1.1.7\n",
      "conda                              4.10.3\n",
      "conda-build                        3.20.5\n",
      "conda-content-trust                0+unknown\n",
      "conda-package-handling             1.7.2\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "contextlib2                        0.6.0.post1\n",
      "cryptography                       3.1.1\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.21\n",
      "cytoolz                            0.11.0\n",
      "dask                               2.30.0\n",
      "decorator                          4.4.2\n",
      "defusedxml                         0.6.0\n",
      "diff-match-patch                   20200713\n",
      "distributed                        2.30.1\n",
      "docutils                           0.16\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.0.1\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.0.12\n",
      "flake8                             3.8.4\n",
      "Flask                              1.1.2\n",
      "fsspec                             0.8.3\n",
      "future                             0.18.2\n",
      "gevent                             20.9.0\n",
      "glob2                              0.7\n",
      "greenlet                           0.4.17\n",
      "h5py                               2.10.0\n",
      "HeapDict                           1.0.1\n",
      "html2text                          2020.1.16\n",
      "html5lib                           1.1\n",
      "hyperopt                           0.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.idna                               2.10\n",
      "\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 2.0.0\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          5.3.4\n",
      "ipython                            7.19.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.5.1\n",
      "isort                              5.6.4\n",
      "itsdangerous                       1.1.0\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.17.1\n",
      "Jinja2                             2.11.2\n",
      "joblib                             0.17.0\n",
      "json5                              0.9.5\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.7\n",
      "jupyter-console                    6.2.0\n",
      "jupyter-core                       4.6.3\n",
      "jupyterlab                         2.2.6\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  1.2.0\n",
      "keyring                            21.4.0\n",
      "kiwisolver                         1.3.0\n",
      "lazy-object-proxy                  1.4.3\n",
      "libarchive-c                       2.9\n",
      "lightgbm                           3.2.1\n",
      "llvmlite                           0.34.0\n",
      "locket                             0.2.0\n",
      "lxml                               4.6.1\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.3.2\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.16\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.2.0\n",
      "mkl-random                         1.1.1\n",
      "mkl-service                        2.3.0\n",
      "mock                               4.0.2\n",
      "more-itertools                     8.6.0\n",
      "mpmath                             1.1.0\n",
      "msgpack                            1.0.0\n",
      "multipledispatch                   0.6.0\n",
      "multitasking                       0.0.9\n",
      "navigator-updater                  0.2.1\n",
      "nbclient                           0.5.1\n",
      "nbconvert                          6.0.7\n",
      "nbformat                           5.0.8\n",
      "nest-asyncio                       1.4.2\n",
      "networkx                           2.5\n",
      "nltk                               3.5\n",
      "nose                               1.3.7\n",
      "notebook                           6.1.4\n",
      "numba                              0.51.2\n",
      "numexpr                            2.7.1\n",
      "numpy                              1.19.2\n",
      "numpydoc                           1.1.0\n",
      "olefile                            0.46\n",
      "openpyxl                           3.0.5\n",
      "pa                                 0.0.23.dev0\n",
      "packaging                          20.4\n",
      "pandas                             1.1.3\n",
      "pandas-datareader                  0.10.0\n",
      "pandocfilters                      1.4.3\n",
      "paramiko                           2.7.2\n",
      "parso                              0.7.0\n",
      "partd                              1.1.0\n",
      "path                               15.0.0\n",
      "pathlib2                           2.3.5\n",
      "pathtools                          0.1.2\n",
      "patsy                              0.5.1\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.0.1\n",
      "pip                                20.2.4\n",
      "pkginfo                            1.6.1\n",
      "plotly                             5.4.0\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "prometheus-client                  0.8.0\n",
      "prompt-toolkit                     3.0.8\n",
      "psutil                             5.7.2\n",
      "py                                 1.9.0\n",
      "pyarrow                            6.0.0\n",
      "pycodestyle                        2.6.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycurl                             7.43.0.6\n",
      "pydocstyle                         5.1.1\n",
      "pyflakes                           2.2.0\n",
      "Pygments                           2.7.2\n",
      "pylint                             2.6.0\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          19.1.0\n",
      "pyparsing                          2.4.7\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.17.3\n",
      "PySocks                            1.7.1\n",
      "pytest                             0.0.0\n",
      "python-dateutil                    2.8.1\n",
      "python-jsonrpc-server              0.4.0\n",
      "python-language-server             0.35.1\n",
      "pytz                               2020.1\n",
      "PyWavelets                         1.1.1\n",
      "pywin32                            227\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.7\n",
      "PyYAML                             5.3.1\n",
      "pyzmq                              19.0.2\n",
      "QDarkStyle                         2.8.1\n",
      "qeds                               0.7.0\n",
      "QtAwesome                          1.0.1\n",
      "qtconsole                          4.7.7\n",
      "QtPy                               1.9.0\n",
      "Quandl                             3.7.0\n",
      "quantecon                          0.5.2\n",
      "regex                              2020.10.15\n",
      "requests                           2.24.0\n",
      "rope                               0.18.0\n",
      "Rtree                              0.9.4\n",
      "ruamel-yaml                        0.15.87\n",
      "scikit-image                       0.17.2\n",
      "scikit-learn                       1.0.1\n",
      "scipy                              1.5.2\n",
      "seaborn                            0.11.0\n",
      "Send2Trash                         1.5.0\n",
      "setuptools                         50.3.1.post20201107\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.4.0.3\n",
      "sip                                4.19.13\n",
      "six                                1.15.0\n",
      "snowballstemmer                    2.0.0\n",
      "sortedcollections                  1.2.1\n",
      "sortedcontainers                   2.2.2\n",
      "soupsieve                          2.0.1\n",
      "Sphinx                             3.2.1\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             1.0.3\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.4\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             4.1.5\n",
      "spyder-kernels                     1.9.4\n",
      "SQLAlchemy                         1.3.20\n",
      "statsmodels                        0.12.0\n",
      "sympy                              1.6.2\n",
      "ta                                 0.7.0\n",
      "tables                             3.6.1\n",
      "tabulate                           0.8.9\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.0.1\n",
      "terminado                          0.9.1\n",
      "testpath                           0.4.4\n",
      "threadpoolctl                      2.1.0\n",
      "tifffile                           2020.10.1\n",
      "toml                               0.10.1\n",
      "toolz                              0.11.1\n",
      "tornado                            6.0.4\n",
      "tqdm                               4.50.2\n",
      "traitlets                          5.0.5\n",
      "typing-extensions                  3.7.4.3\n",
      "ujson                              4.0.1\n",
      "unicodecsv                         0.14.1\n",
      "urllib3                            1.25.11\n",
      "watchdog                           0.10.3\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "Werkzeug                           1.0.1\n",
      "wheel                              0.35.1\n",
      "widgetsnbextension                 3.5.1\n",
      "win-inet-pton                      1.1.0\n",
      "win-unicode-console                0.5\n",
      "wincertstore                       0.2\n",
      "wordcloud                          1.8.1\n",
      "wrapt                              1.11.2\n",
      "xlrd                               1.2.0\n",
      "XlsxWriter                         1.3.7\n",
      "xlwings                            0.20.8\n",
      "xlwt                               1.3.0\n",
      "xmltodict                          0.12.0\n",
      "yapf                               0.30.0\n",
      "yfinance                           0.1.59\n",
      "zict                               2.0.0\n",
      "zipp                               3.4.0\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.1.2\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as it has worked properly, since we can find the previous packages in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessary Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # this module allows us to store training date into a file and therefore run more quickly previous code\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn import (\n",
    "    model_selection, linear_model, ensemble, metrics, neural_network, pipeline, model_selection, \\\n",
    "    tree, preprocessing, pipeline\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold #as opposed to KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparatory work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"JSTdatasetR4.xlsx\",sheet_name=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the desired variables in a new Data Frame (some changes compared to what was recommended in the pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the original:\n",
      "   year    country  iso  ifs     pop      rgdpmad     rgdppc     rconpc  \\\n",
      "0  1870  Australia  AUS  193  1775.0  3273.239437  13.836157  21.449734   \n",
      "1  1871  Australia  AUS  193  1675.0  3298.507463  13.936864  19.930801   \n",
      "2  1872  Australia  AUS  193  1722.0  3553.426249  15.044247  21.085006   \n",
      "3  1873  Australia  AUS  193  1769.0  3823.629169  16.219443  23.254910   \n",
      "4  1874  Australia  AUS  193  1822.0  3834.796926  16.268228  23.458050   \n",
      "\n",
      "      gdp        iy  ...  eq_capgain     eq_dp  eq_capgain_interp  \\\n",
      "0  208.78  0.109266  ...   -0.070045  0.071417                NaN   \n",
      "1  211.56  0.104579  ...    0.041654  0.065466                NaN   \n",
      "2  227.40  0.130438  ...    0.108945  0.062997                NaN   \n",
      "3  266.54  0.124986  ...    0.083086  0.064484                NaN   \n",
      "4  287.58  0.141960  ...    0.119389  0.063503                NaN   \n",
      "\n",
      "   eq_tr_interp  eq_dp_interp  bond_rate  eq_div_rtn  capital_tr  risky_tr  \\\n",
      "0           NaN           NaN   0.049118    0.066415         NaN       NaN   \n",
      "1           NaN           NaN   0.048446    0.068193         NaN       NaN   \n",
      "2           NaN           NaN   0.047373    0.069861         NaN       NaN   \n",
      "3           NaN           NaN   0.046720    0.069842         NaN       NaN   \n",
      "4           NaN           NaN   0.046533    0.071085         NaN       NaN   \n",
      "\n",
      "   safe_tr  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "this is the copy:\n",
      "   year    country  iso  ifs     pop      rgdpmad     rgdppc     rconpc  \\\n",
      "0  1870  Australia  AUS  193  1775.0  3273.239437  13.836157  21.449734   \n",
      "1  1871  Australia  AUS  193  1675.0  3298.507463  13.936864  19.930801   \n",
      "2  1872  Australia  AUS  193  1722.0  3553.426249  15.044247  21.085006   \n",
      "3  1873  Australia  AUS  193  1769.0  3823.629169  16.219443  23.254910   \n",
      "4  1874  Australia  AUS  193  1822.0  3834.796926  16.268228  23.458050   \n",
      "\n",
      "      gdp        iy  ...  eq_capgain     eq_dp  eq_capgain_interp  \\\n",
      "0  208.78  0.109266  ...   -0.070045  0.071417                NaN   \n",
      "1  211.56  0.104579  ...    0.041654  0.065466                NaN   \n",
      "2  227.40  0.130438  ...    0.108945  0.062997                NaN   \n",
      "3  266.54  0.124986  ...    0.083086  0.064484                NaN   \n",
      "4  287.58  0.141960  ...    0.119389  0.063503                NaN   \n",
      "\n",
      "   eq_tr_interp  eq_dp_interp  bond_rate  eq_div_rtn  capital_tr  risky_tr  \\\n",
      "0           NaN           NaN   0.049118    0.066415         NaN       NaN   \n",
      "1           NaN           NaN   0.048446    0.068193         NaN       NaN   \n",
      "2           NaN           NaN   0.047373    0.069861         NaN       NaN   \n",
      "3           NaN           NaN   0.046720    0.069842         NaN       NaN   \n",
      "4           NaN           NaN   0.046533    0.071085         NaN       NaN   \n",
      "\n",
      "   safe_tr  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "this is the copy with all of the variables we have added:\n",
      "   year    country  iso  ifs     pop      rgdpmad     rgdppc     rconpc  \\\n",
      "0  1870  Australia  AUS  193  1775.0  3273.239437  13.836157  21.449734   \n",
      "1  1871  Australia  AUS  193  1675.0  3298.507463  13.936864  19.930801   \n",
      "2  1872  Australia  AUS  193  1722.0  3553.426249  15.044247  21.085006   \n",
      "3  1873  Australia  AUS  193  1769.0  3823.629169  16.219443  23.254910   \n",
      "4  1874  Australia  AUS  193  1822.0  3834.796926  16.268228  23.458050   \n",
      "\n",
      "      gdp        iy  ...  curr_acc_gdp  delta_credit  delta_debt_serv_ratio  \\\n",
      "0  208.78  0.109266  ...     -0.029445           NaN                    NaN   \n",
      "1  211.56  0.104579  ...      0.024867     -0.008383              -0.000582   \n",
      "2  227.40  0.130438  ...      0.034598     -0.008576              -0.000679   \n",
      "3  266.54  0.124986  ...     -0.041449     -0.000188              -0.000169   \n",
      "4  287.58  0.141960  ...     -0.019348      0.003258               0.000106   \n",
      "\n",
      "   delta_investm_ratio  delta_pdebt_ratio  delta_bmoney_gdp  \\\n",
      "0                  NaN                NaN               NaN   \n",
      "1            -0.004687           0.019231          0.021162   \n",
      "2             0.025859          -0.036879          0.019987   \n",
      "3            -0.005452          -0.012228         -0.024725   \n",
      "4             0.016974           0.051630         -0.000757   \n",
      "\n",
      "   delta_curr_acc_gdp  growth_cpi  growth_cons  crisis_warning  \n",
      "0                 NaN         NaN          NaN               0  \n",
      "1            0.054312   -0.015384    -0.070814               0  \n",
      "2            0.009732   -0.046875     0.057911               0  \n",
      "3           -0.076047    0.000000     0.102912               0  \n",
      "4            0.022102    0.049180     0.008735               0  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "this is the smaller dataframe with just the variables we are interested in:\n",
      "   slope_yield_curve  delta_credit  delta_debt_serv_ratio  \\\n",
      "1           0.002446     -0.008383              -0.000582   \n",
      "2           0.001373     -0.008576              -0.000679   \n",
      "3           0.002720     -0.000188              -0.000169   \n",
      "4           0.001533      0.003258               0.000106   \n",
      "5          -0.000927      0.017308               0.000417   \n",
      "\n",
      "   delta_investm_ratio  delta_pdebt_ratio  delta_bmoney_gdp  \\\n",
      "1            -0.004687           0.019231          0.021162   \n",
      "2             0.025859          -0.036879          0.019987   \n",
      "3            -0.005452          -0.012228         -0.024725   \n",
      "4             0.016974           0.051630         -0.000757   \n",
      "5             0.018604           0.039365          0.018525   \n",
      "\n",
      "   delta_curr_acc_gdp  growth_cpi  growth_cons     eq_tr  crisis_warning  \n",
      "1            0.054312   -0.015384    -0.070814  0.110193               0  \n",
      "2            0.009732   -0.046875     0.057911  0.176749               0  \n",
      "3           -0.076047    0.000000     0.102912  0.151686               0  \n",
      "4            0.022102    0.049180     0.008735  0.191481               0  \n",
      "5           -0.006950    0.031250     0.094273  0.124408               0  \n",
      "this is the previous dataframe, but it includes the year:\n",
      "   year  slope_yield_curve  delta_credit  delta_debt_serv_ratio  \\\n",
      "1  1871           0.002446     -0.008383              -0.000582   \n",
      "2  1872           0.001373     -0.008576              -0.000679   \n",
      "3  1873           0.002720     -0.000188              -0.000169   \n",
      "4  1874           0.001533      0.003258               0.000106   \n",
      "5  1875          -0.000927      0.017308               0.000417   \n",
      "\n",
      "   delta_investm_ratio  delta_pdebt_ratio  delta_bmoney_gdp  \\\n",
      "1            -0.004687           0.019231          0.021162   \n",
      "2             0.025859          -0.036879          0.019987   \n",
      "3            -0.005452          -0.012228         -0.024725   \n",
      "4             0.016974           0.051630         -0.000757   \n",
      "5             0.018604           0.039365          0.018525   \n",
      "\n",
      "   delta_curr_acc_gdp  growth_cpi  growth_cons     eq_tr  crisis_warning  \n",
      "1            0.054312   -0.015384    -0.070814  0.110193               0  \n",
      "2            0.009732   -0.046875     0.057911  0.176749               0  \n",
      "3           -0.076047    0.000000     0.102912  0.151686               0  \n",
      "4            0.022102    0.049180     0.008735  0.191481               0  \n",
      "5           -0.006950    0.031250     0.094273  0.124408               0  \n"
     ]
    }
   ],
   "source": [
    "#let's make a copy, in order to preserve the original dataset\n",
    "df_copy=df.copy()\n",
    "print(\"this is the original:\") #added\n",
    "print(df.head()) #added\n",
    "print(\"this is the copy:\") #added\n",
    "df_copy.head() #added\n",
    "print(df_copy.head())\n",
    "\n",
    "#let's create new (temporary) columns with the transformed variables we need:\n",
    "#-slope of the yield curve\n",
    "df_copy[\"slope_yield_curve\"]=df_copy[\"ltrate\"]/100-df_copy[\"stir\"]/100\n",
    "\n",
    "#-credit: loans to the privete sector / gdp\n",
    "df_copy[\"credit\"]=df_copy[\"tloans\"]/df_copy[\"gdp\"]\n",
    "\n",
    "#-debt service ratio: credit * long term interest rate\n",
    "df_copy[\"debt_serv_ratio\"]= (df_copy[\"tloans\"]/df_copy[\"gdp\"])*df_copy[\"ltrate\"]/100\n",
    "\n",
    "#-broad money over gdp\n",
    "df_copy[\"bmoney_gdp\"]=df_copy[\"money\"]/df_copy[\"gdp\"]\n",
    "\n",
    "#-current account over gdp\n",
    "df_copy[\"curr_acc_gdp\"]=df_copy[\"ca\"]/df_copy[\"gdp\"]\n",
    "\n",
    "\n",
    "# Now we need to compute 1-year absolute variations and percentage variations for a few variables\n",
    "# Obviously this must be done country-wise, so we cannot act on the dataframe as it is.\n",
    "# a Convenient way of doing this is the Pandas method 'groupby()'\n",
    "df_copy_group=df_copy.groupby(\"iso\") # 'iso' is the country code\n",
    "\n",
    "# create 1 year-variation of credit from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"delta_credit\"]=df_copy_group[\"credit\"].diff(periods=1)\n",
    "\n",
    "# create 1 year-variation of debt ser ratio from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"delta_debt_serv_ratio\"]=df_copy_group[\"debt_serv_ratio\"].diff(periods=1)\n",
    "\n",
    "# create 1 year-variation of investment/gdp from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"delta_investm_ratio\"]=df_copy_group[\"iy\"].diff(periods=1)\n",
    "\n",
    "# create 1 year-variation of public debt/gdp from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"delta_pdebt_ratio\"]=df_copy_group[\"debtgdp\"].diff(periods=1)\n",
    "\n",
    "# create 1 year-variation of broad money / gdp from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"delta_bmoney_gdp\"]=df_copy_group[\"bmoney_gdp\"].diff(periods=1)\n",
    "\n",
    "# create 1 year-variation of current / gdp from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"delta_curr_acc_gdp\"]=df_copy_group[\"curr_acc_gdp\"].diff(periods=1)\n",
    "\n",
    "# now we need to create new variables which are 1-year growth rates of existing ones\n",
    "# we will need this function to apply to the columns of the dataframe\n",
    "def lag_pct_change(x):\n",
    "    \"\"\" Computes percentage changes \"\"\"\n",
    "    lag = np.array(pd.Series(x).shift(1))\n",
    "    return ((x - lag) / lag) #brackets added\n",
    "\n",
    "\n",
    "# create 1 year growth rate of CPI from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"growth_cpi\"]=df_copy_group[\"cpi\"].apply(lag_pct_change)\n",
    "\n",
    "# create 1 year growth rate of consumption per capita from grouped dataframe and add back to initial dataframe\n",
    "df_copy[\"growth_cons\"]=df_copy_group[\"rconpc\"].apply(lag_pct_change)\n",
    "\n",
    "# Now let's create the crises early warning label: a dummy variable which takes value one if in the next year or two there will be a crises\n",
    "# temporary array of zeros, dimension = number of rows in database\n",
    "temp_array=np.zeros(len(df_copy))\n",
    "\n",
    "# loop to create dummy\n",
    "for i in np.arange(0,len(df_copy)-2):\n",
    "    temp_array[i]= 1 \\\n",
    "    if ( (df_copy.loc[i+1,'crisisJST']== 1) or (df_copy.loc[i+2,'crisisJST']== 1) ) else 0\n",
    "\n",
    "#put the dummy in the dataframe\n",
    "df_copy[\"crisis_warning\"]=temp_array.astype(\"int64\")\n",
    "print(\"this is the copy with all of the variables we have added:\")\n",
    "print(df_copy.head())\n",
    "\n",
    "# create a smaller dataframe including only the variables we are interested in: the first ten are predictors (X) and the last one is the output, or label (y). Also, drop the observations where some variable is missing\n",
    "variables=[\"slope_yield_curve\",\"delta_credit\",\"delta_debt_serv_ratio\",\"delta_investm_ratio\",\"delta_pdebt_ratio\",\"delta_bmoney_gdp\",\"delta_curr_acc_gdp\",\"growth_cpi\",\"growth_cons\",\"eq_tr\",\"crisis_warning\"]\n",
    "df_final=df_copy[variables].dropna()\n",
    "print(\"this is the smaller dataframe with just the variables we are interested in:\")\n",
    "print(df_final.head())\n",
    "\n",
    "# let's also create a version of our dataframe which includes the year\n",
    "df_final_withyear=df_copy[[\"year\"]+variables].dropna()\n",
    "print(\"this is the previous dataframe, but it includes the year:\")\n",
    "print(df_final_withyear.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrization\n",
    "In this section we will assign functions for the parametrization needed in splitting. Not just for random splitting of test and training sets, but also for kfolds which ae used to test models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent_test is set to 0.25\n",
      "number_of_splits is set to 5\n"
     ]
    }
   ],
   "source": [
    "# Percentage test dataset \n",
    "percent_test = 0.25\n",
    "print(\"percent_test is set to \" + str(percent_test))\n",
    "\n",
    "# Cross-Validation Splits\n",
    "number_of_splits = 5\n",
    "kf = StratifiedKFold(n_splits=number_of_splits)\n",
    "print(\"number_of_splits is set to \" + str(number_of_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions are needed to plot the trees-graphs \n",
    "def surface_scatter_plot(X,y,f, ngrid=50, width=860, height=700): \n",
    "    scatter = go.Scatter3d(x=X.iloc[:,0],y=X.iloc[:,1],z=y,\n",
    "                           mode='markers',\n",
    "                           marker=dict(size=2, opacity=0.3)\n",
    "                        )\n",
    "\n",
    "    xlo=X.min()\n",
    "    xhi=X.max()\n",
    "    xgrid = np.linspace(xlo,xhi,ngrid)\n",
    "    ey = np.zeros((len(xgrid),len(xgrid)))\n",
    "    colorscale = [[0, colors[0]], [1, colors[2]]]\n",
    "    for i in range(len(xgrid)):\n",
    "        for j in range(len(xgrid)):\n",
    "            ey[j,i] = f([xgrid[i],xgrid[j]])\n",
    "    \n",
    "    surface = go.Surface(x=xgrid, y=xgrid, z=ey, colorscale=colorscale, opacity=1.0)\n",
    "    \n",
    "    fig = go.FigureWidget(\n",
    "        data=layers,\n",
    "        layout = go.Layout(\n",
    "            autosize=True,\n",
    "            scene=dict(\n",
    "                xaxis_title='X1',\n",
    "                yaxis_title='X2',\n",
    "                zaxis_title='Y'\n",
    "            ),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            template=plotly_template,\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_roc(mod, X, y):\n",
    "    # predicted_probs is an N x 2 array, where N is number of observations and 2 is number of classes\n",
    "    predicted_probs = mod.predict_proba(X_test)\n",
    "\n",
    "    # keep the second column, for label=1\n",
    "    predicted_prob1 = predicted_probs[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, predicted_prob1)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, 1], [0, 1], \"k--\")\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2499 entries, 0 to 2498\n",
      "Data columns (total 65 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   year                      2499 non-null   int64  \n",
      " 1   country                   2499 non-null   object \n",
      " 2   iso                       2499 non-null   object \n",
      " 3   ifs                       2499 non-null   int64  \n",
      " 4   pop                       2499 non-null   float64\n",
      " 5   rgdpmad                   2499 non-null   float64\n",
      " 6   rgdppc                    2499 non-null   float64\n",
      " 7   rconpc                    2411 non-null   float64\n",
      " 8   gdp                       2474 non-null   float64\n",
      " 9   iy                        2279 non-null   float64\n",
      " 10  cpi                       2499 non-null   float64\n",
      " 11  ca                        2344 non-null   float64\n",
      " 12  imports                   2458 non-null   float64\n",
      " 13  exports                   2458 non-null   float64\n",
      " 14  narrowm                   2435 non-null   float64\n",
      " 15  money                     2349 non-null   float64\n",
      " 16  stir                      2351 non-null   float64\n",
      " 17  ltrate                    2464 non-null   float64\n",
      " 18  debtgdp                   2322 non-null   float64\n",
      " 19  revenue                   2398 non-null   float64\n",
      " 20  expenditure               2417 non-null   float64\n",
      " 21  xrusd                     2496 non-null   float64\n",
      " 22  peg                       2499 non-null   int64  \n",
      " 23  peg_strict                2499 non-null   int64  \n",
      " 24  crisisJST                 2499 non-null   int64  \n",
      " 25  tloans                    2311 non-null   float64\n",
      " 26  tmort                     2186 non-null   float64\n",
      " 27  thh                       1309 non-null   float64\n",
      " 28  tbus                      1234 non-null   float64\n",
      " 29  hpnom                     1906 non-null   float64\n",
      " 30  peg_type                  2499 non-null   object \n",
      " 31  peg_base                  2300 non-null   object \n",
      " 32  eq_tr                     2183 non-null   float64\n",
      " 33  housing_tr                1829 non-null   float64\n",
      " 34  bond_tr                   2215 non-null   float64\n",
      " 35  bill_rate                 2272 non-null   float64\n",
      " 36  rent_ipolated             29 non-null     float64\n",
      " 37  housing_capgain_ipolated  5 non-null      float64\n",
      " 38  housing_capgain           2053 non-null   float64\n",
      " 39  housing_rent_rtn          1829 non-null   float64\n",
      " 40  housing_rent_yd           1841 non-null   float64\n",
      " 41  eq_capgain                2236 non-null   float64\n",
      " 42  eq_dp                     2089 non-null   float64\n",
      " 43  eq_capgain_interp         7 non-null      float64\n",
      " 44  eq_tr_interp              7 non-null      float64\n",
      " 45  eq_dp_interp              6 non-null      float64\n",
      " 46  bond_rate                 2301 non-null   float64\n",
      " 47  eq_div_rtn                2083 non-null   float64\n",
      " 48  capital_tr                1763 non-null   float64\n",
      " 49  risky_tr                  1786 non-null   float64\n",
      " 50  safe_tr                   2168 non-null   float64\n",
      " 51  slope_yield_curve         2325 non-null   float64\n",
      " 52  credit                    2291 non-null   float64\n",
      " 53  debt_serv_ratio           2269 non-null   float64\n",
      " 54  bmoney_gdp                2328 non-null   float64\n",
      " 55  curr_acc_gdp              2339 non-null   float64\n",
      " 56  delta_credit              2262 non-null   float64\n",
      " 57  delta_debt_serv_ratio     2239 non-null   float64\n",
      " 58  delta_investm_ratio       2247 non-null   float64\n",
      " 59  delta_pdebt_ratio         2291 non-null   float64\n",
      " 60  delta_bmoney_gdp          2303 non-null   float64\n",
      " 61  delta_curr_acc_gdp        2308 non-null   float64\n",
      " 62  growth_cpi                2482 non-null   float64\n",
      " 63  growth_cons               2394 non-null   float64\n",
      " 64  crisis_warning            2499 non-null   int64  \n",
      "dtypes: float64(55), int64(6), object(4)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_copy.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split sample (test and training sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape\n",
      "(2499, 51)\n",
      "head\n",
      "   year    country  iso  ifs     pop      rgdpmad     rgdppc     rconpc  \\\n",
      "0  1870  Australia  AUS  193  1775.0  3273.239437  13.836157  21.449734   \n",
      "1  1871  Australia  AUS  193  1675.0  3298.507463  13.936864  19.930801   \n",
      "2  1872  Australia  AUS  193  1722.0  3553.426249  15.044247  21.085006   \n",
      "3  1873  Australia  AUS  193  1769.0  3823.629169  16.219443  23.254910   \n",
      "4  1874  Australia  AUS  193  1822.0  3834.796926  16.268228  23.458050   \n",
      "\n",
      "      gdp        iy  ...  eq_capgain     eq_dp  eq_capgain_interp  \\\n",
      "0  208.78  0.109266  ...   -0.070045  0.071417                NaN   \n",
      "1  211.56  0.104579  ...    0.041654  0.065466                NaN   \n",
      "2  227.40  0.130438  ...    0.108945  0.062997                NaN   \n",
      "3  266.54  0.124986  ...    0.083086  0.064484                NaN   \n",
      "4  287.58  0.141960  ...    0.119389  0.063503                NaN   \n",
      "\n",
      "   eq_tr_interp  eq_dp_interp  bond_rate  eq_div_rtn  capital_tr  risky_tr  \\\n",
      "0           NaN           NaN   0.049118    0.066415         NaN       NaN   \n",
      "1           NaN           NaN   0.048446    0.068193         NaN       NaN   \n",
      "2           NaN           NaN   0.047373    0.069861         NaN       NaN   \n",
      "3           NaN           NaN   0.046720    0.069842         NaN       NaN   \n",
      "4           NaN           NaN   0.046533    0.071085         NaN       NaN   \n",
      "\n",
      "   safe_tr  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "df_final.columns\n",
      "Index(['slope_yield_curve', 'delta_credit', 'delta_debt_serv_ratio',\n",
      "       'delta_investm_ratio', 'delta_pdebt_ratio', 'delta_bmoney_gdp',\n",
      "       'delta_curr_acc_gdp', 'growth_cpi', 'growth_cons', 'eq_tr',\n",
      "       'crisis_warning'],\n",
      "      dtype='object')\n",
      "X.columns\n",
      "Index(['slope_yield_curve', 'delta_credit', 'delta_debt_serv_ratio',\n",
      "       'delta_investm_ratio', 'delta_pdebt_ratio', 'delta_bmoney_gdp',\n",
      "       'delta_curr_acc_gdp', 'growth_cpi', 'growth_cons', 'eq_tr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# First we will take a look at the dataset to get an impression of its structure first -> df.shape will return (x1, x2), where x1=nrrows and x2=nrcolumns\n",
    "print(\"shape\")\n",
    "print(df.shape)\n",
    "print(\"head\")\n",
    "print(df.head())\n",
    "print(\"df_final.columns\")\n",
    "print(df_final.columns)\n",
    "X = df_final.drop(\"crisis_warning\", axis=1)\n",
    "print(\"X.columns\")\n",
    "print(X.columns) #little redundant as X=df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final[\"crisis_warning\"] \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if the plit worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observation = 1680\n",
      "1680\n",
      "number of obs. in test data set should be 420.0\n",
      "number of obs. in test data set is 420\n",
      "number of obs. in training data set should be 1260.0\n",
      "number of obs. in training data set is 1260\n"
     ]
    }
   ],
   "source": [
    "N=len(X)\n",
    "print(\"number of observation = \" + str(N))\n",
    "N2= len(X_test) + len(X_train)\n",
    "print(N2)\n",
    "ptimesN=percent_test*N\n",
    "oneminusptimesN=(1-percent_test)*N\n",
    "print(\"number of obs. in test data set should be \" + str(ptimesN))\n",
    "print(\"number of obs. in test data set is \" + str(len(X_test))) #should equal to (1-percent_test)*N\n",
    "print(\"number of obs. in training data set should be \" + str(oneminusptimesN))\n",
    "print(\"number of obs. in training data set is \" + str(len(X_train))) #should equal to percent_test*N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Fitting of modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.) Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from previous code that:\n",
    "- X = df_final.drop(\"crisis_warning\", axis=1) (code line 14)\n",
    "- y = df_final[\"crisis_warning\"] (code line 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: y(x) = -2.6246 + -0.6531 X\n"
     ]
    }
   ],
   "source": [
    "logistic_model = linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "beta_0 = logistic_model.intercept_[0]\n",
    "beta_1 = logistic_model.coef_[0][0]\n",
    "print(f\"Logistic regression: y(x) = {beta_0:.4f} + {beta_1:.4f} X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative version in which we can see all coefficients individually (better option for answering question 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.400266\n",
      "         Iterations 8\n",
      "                             Results: Logit\n",
      "=========================================================================\n",
      "Model:                 Logit               Pseudo R-squared:    -0.520   \n",
      "Dependent Variable:    crisis_warning      AIC:                 1028.6704\n",
      "Date:                  2021-12-03 15:28    BIC:                 1080.0591\n",
      "No. Observations:      1260                Log-Likelihood:      -504.34  \n",
      "Df Model:              9                   LL-Null:             -331.86  \n",
      "Df Residuals:          1250                LLR p-value:         1.0000   \n",
      "Converged:             1.0000              Scale:               1.0000   \n",
      "No. Iterations:        8.0000                                            \n",
      "-------------------------------------------------------------------------\n",
      "                       Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "-------------------------------------------------------------------------\n",
      "slope_yield_curve     -39.6666   4.8123  -8.2428 0.0000 -49.0984 -30.2347\n",
      "delta_credit           -5.4177   2.8064  -1.9305 0.0535 -10.9180   0.0827\n",
      "delta_debt_serv_ratio  35.4567  15.8503   2.2370 0.0253   4.3907  66.5228\n",
      "delta_investm_ratio    15.9697   4.5048   3.5450 0.0004   7.1404  24.7989\n",
      "delta_pdebt_ratio      -3.7222   1.4743  -2.5248 0.0116  -6.6118  -0.8327\n",
      "delta_bmoney_gdp      -12.1142   2.8752  -4.2134 0.0000 -17.7494  -6.4790\n",
      "delta_curr_acc_gdp     -9.8365   3.5689  -2.7562 0.0058 -16.8313  -2.8416\n",
      "growth_cpi            -22.0442   1.8301 -12.0452 0.0000 -25.6311 -18.4572\n",
      "growth_cons           -22.9897   2.3457  -9.8006 0.0000 -27.5873 -18.3922\n",
      "eq_tr                  -2.7102   0.4619  -5.8680 0.0000  -3.6155  -1.8050\n",
      "=========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "# used the instructions of the following website: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.) Logistic regression with LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.35593916e+01,  9.82545373e+00,  6.77380718e+01,\n",
       "         1.67866194e+01, -6.64037236e+00,  3.06020818e+00,\n",
       "         1.30441532e+00, -2.54070430e+00, -1.06442667e+01,\n",
       "         5.08466184e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "# candidate regularization parameters, smaller means heavier penalty, thus coefficients more shrinked to zero.\n",
    "C_values = [0.001, 0.01, 0.05, 0.1, 1., 100.]\n",
    "# define model\n",
    "my_l1reg_logistic = LogisticRegressionCV(Cs=C_values, cv=n_folds, penalty='l1', \n",
    "                           refit=True, scoring='roc_auc', \n",
    "                           solver='liblinear', random_state=0,\n",
    "                           fit_intercept=True)\n",
    "# fit the model\n",
    "my_l1reg_logistic.fit(X_train, y_train)\n",
    "# these are already the best coefficients\n",
    "coefs = my_l1reg_logistic.coef_\n",
    "# mean of scores of class \"1\"\n",
    "scores = my_l1reg_logistic.scores_[1]\n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "# from this, you can visually inspect which C_value has the highest average score, thus is selected by the cross-validation\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.) Random trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by fitting a tree to this simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Simulate some data and plot it\n",
    "n = 1000\n",
    "Xsim = np.random.rand(n,2)\n",
    "def Ey_x(x):\n",
    "    return 1/3*(np.sin(5*x[0])*np.sqrt(x[1])*np.exp(-(x[1]-0.5)**2))\n",
    "\n",
    "ysim = np.apply_along_axis(Ey_x, 1, Xsim) + np.random.randn(n)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5e8a6bb05661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurface_scatter_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXsim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mysim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEy_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-5e8a6bb05661>\u001b[0m in \u001b[0;36msurface_scatter_plot\u001b[1;34m(X, y, f, xlo, xhi, ngrid, width, height, f0, show_f0)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mey0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcolorscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colors' is not defined"
     ]
    }
   ],
   "source": [
    "def surface_scatter_plot(X,y,f, xlo=0., xhi=1., ngrid=50,\n",
    "                         width=860, height=700, f0=Ey_x, show_f0=False):\n",
    "    scatter = go.Scatter3d(x=X[:,0],y=X[:,1],z=y,\n",
    "                           mode='markers',\n",
    "                           marker=dict(size=2, opacity=0.3)\n",
    "    )\n",
    "    xgrid = np.linspace(xlo,xhi,ngrid)\n",
    "    ey = np.zeros((len(xgrid),len(xgrid)))\n",
    "    ey0 = np.zeros((len(xgrid),len(xgrid)))\n",
    "    colorscale = [[0, colors[0]], [1, colors[2]]]\n",
    "    for i in range(len(xgrid)):\n",
    "        for j in range(len(xgrid)):\n",
    "            ey[j,i] = f([xgrid[i],xgrid[j]])\n",
    "            ey0[j,i]= f0([xgrid[i],xgrid[j]])\n",
    "    surface = go.Surface(x=xgrid, y=xgrid, z=ey, colorscale=colorscale, opacity=1.0)\n",
    "    if (show_f0):\n",
    "        surface0 = go.Surface(x=xgrid, y=xgrid, z=ey0, opacity=0.8, colorscale=colorscale)\n",
    "        layers = [scatter, surface, surface0]\n",
    "    else:\n",
    "        layers = [scatter, surface]\n",
    "    fig = go.FigureWidget(\n",
    "        data=layers,\n",
    "        layout = go.Layout(\n",
    "            autosize=True,\n",
    "            scene=dict(\n",
    "                xaxis_title='X1',\n",
    "                yaxis_title='X2',\n",
    "                zaxis_title='Y'\n",
    "            ),\n",
    "            width=width,\n",
    "            height=height,\n",
    "            template=plotly_template,\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = surface_scatter_plot(Xsim, ysim, Ey_x)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.) Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "surface_scatter_plot() got an unexpected keyword argument 'show_f0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8459becb86a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m fig=surface_scatter_plot(X_train,y_train,lambda x: forest.predict([x]),\n\u001b[0m\u001b[0;32m      4\u001b[0m                          show_f0=True)\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: surface_scatter_plot() got an unexpected keyword argument 'show_f0'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators = 10).fit(X_train,y_train)\n",
    "fig=surface_scatter_plot(X_train,y_train,lambda x: forest.predict([x]),\n",
    "                         show_f0=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.) Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-689608a71e4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     print(\"we  look at the following combinations of neurons per layer: \" + str(i) + \"+\" + str(j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrneurons_1stlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrneurons_2ndlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"number of hiddenlayers is equal to \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhiddenlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"number of neurons per layer is equal to \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"and \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"respect.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "hiddenlayers = 2\n",
    "nrneurons_1stlayer = np.array([100, 500, 1000]) \n",
    "nrneurons_2ndlayer = np.array([100, 500, 1000]) \n",
    "# The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "\n",
    "#lbfgs is an optimizer in the family of quasi-Newton methods.\n",
    "# Alpha is a parameter for regularization term, aka penalty term, that combats overfitting by constraining the size of the weights.\n",
    "# https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html\n",
    "\n",
    "# for i, j in itertools.product(nrneurons_1stlayer, nrneurons_2ndlayer): #cartesian product \n",
    "#     print(\"we  look at the following combinations of neurons per layer: \" + str(i) + \"+\" + str(j)\n",
    "\n",
    "for i, j in itertools.product(nrneurons_1stlayer, nrneurons_2ndlayer): \n",
    "     print(\"number of hiddenlayers is equal to \"+ str(hiddenlayers))\n",
    "     print(\"number of neurons per layer is equal to \"+ str(i) + \"and \"+ str(j) + \"respect.\")\n",
    "     model5=neural_network.MLPClassifier((i, j), activation=\"logistic\", verbose=True, solver=\"lbfgs\", alpha=0.0)\n",
    "     model5.fit(X_train, y_train)\n",
    "     mse_model5 = metrics.mean_squared_error(y, model5.predict(X))\n",
    "     print(str(mse_model5))\n",
    "\n",
    "\n",
    "hiddenlayers = 1\n",
    "nrneurons_1stlayer = np.array([100, 500, 1000]) \n",
    "\n",
    "for i in nrneurons_1stlayer: \n",
    "     print(\"number of hiddenlayers is equal to \"+ str(hiddenlayers))\n",
    "     print(\"number of neurons per layer is equal to \"+ str(i))\n",
    "     model5=neural_network.MLPClassifier((i), activation=\"logistic\", verbose=True, solver=\"lbfgs\", alpha=0.0)\n",
    "     model5.fit(X_train, y_train)\n",
    "     mse_model5 = metrics.mean_squared_error(y, model5.predict(X))\n",
    "     print(str(mse_model5))\n",
    "    \n",
    "# Standardize \n",
    "print(\"STANDARDIZATION\")\n",
    "model5_scaled = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(),  # this will do the input scaling\n",
    "    neural_network.MLPClassifier((30, 20)) \n",
    ")\n",
    "\n",
    "hiddenlayers = 1\n",
    "nrneurons_1stlayer = np.array([100, 500, 1000]) \n",
    "\n",
    "for i in nrneurons_1stlayer: \n",
    "     print(\"number of hiddenlayers is equal to \"+ str(hiddenlayers))\n",
    "     print(\"number of neurons per layer is equal to \"+ str(i))\n",
    "     model5_scaled=pipeline.make_pipeline(\n",
    "        preprocessing.StandardScaler(),  # this will do the input scaling\n",
    "        neural_network.MLPClassifier((i), activation=\"logistic\", verbose=True, solver=\"lbfgs\", alpha=0.0)\n",
    "        )\n",
    "     model5_scaled.fit(X_train, y_train)\n",
    "     mse_model5_scaled = metrics.mean_squared_error(y, model5_scaled.predict(X))\n",
    "     print(str(mse_model5_scaled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-0cc72afbce4d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-0cc72afbce4d>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    from train_index, test_index in kf.split(ENTER NAME OF DATASET)\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Plot the ROC curves for the best versions of your models and compute the AUROC. \n",
    "\n",
    "# Cross-Validation\n",
    "from train_index, test_index in kf.split(ENTER NAME OF DATASET)\n",
    "print(train_index, test_index)\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(x_test)\n",
    "\n",
    "get_score(LogisticRegression, X_train, X_test, y_train, y_test)\n",
    "\n",
    "for train_index, test_index in kf.split(df_final):\n",
    "    X_train, X_test, y_train, y_test = df_final[train_index], df_final[test_index], df_final[train]  \n",
    "#-------- Confusion Matrices Comparison\n",
    "#Plot the true value of y against the prediced value \n",
    "y_predicted = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('True Value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Which variables 'survive' in the logistic regression with L1 regularization ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the outputs in which we coded the logistic regression with L1 regularization, most coefficients remain at a value very different to 0. \n",
    "Only the last coefficient (eq_tr), which refers to the Nominal Total Equity return. This means that this variable is not a good predictor for whether tere will be an economic crisis, whilst all others are and \"survive\" the L1 regularization.\n",
    "Comparing the coefficient values with and without the L1 regularization, we can see that the beta of each of the variables that survived has changed,including in some cases their sign.\n",
    "- The slope_of_the_yield_curve's coefficient went from a -39,67 to a -23,56. Meaning that even with the regularization, this variable still is quite significant for predicting crisis.\n",
    "- The delta_credit's coefficient went from a -5,42 to a 9,83. With the regularization, whilst the variable remains significant, its impact completly shifts. Whilst previously 1 year-variation of credit led to a lower likelihood of a crisis happening, the opposite occurs with the regularization.\n",
    "- The delta_debt_serv_ratio's coefficient went from a 35,46 to a 67,74. This means that with the L1 regularization the impact of the 1 year-variation of debt ser ratio on the likelihood of a crisis hapenning increased.\n",
    "- The delta_investm_ratio's coefficient went from a 15,97 to a 16,79.  After the L1 regularization, the impact of a 1 year-variation of investment/gdp ratio hasn't changed too much from what was initially predicted.\n",
    "- The delta_pdebt_ratio's coefficient went from a -3,72 to a -6,64. With the L1 regularization, the impact the 1 year-variation of public debt/gdp on the likelihood of a crisis happening has increased.\n",
    "- The delta_bmoney_gdp's coefficient went from a -12,11 to a 3,06. With the L1 regularization, the impact of a 1 year-variation of broad money / gdp has completly shifted. Taking the regularization into account, a higher variation of this variable leads to a higher probability of a crisis happening. We have the opposite effect if we don't consider this.\n",
    "- The delta_curr_acc_gdp's coefficient went from a -9,84 to a 1,30. After the L1 regularization, the impact of 1 year-variation of current / gdp on the likelihood of a crisis happening has shifted - it used to be negative and now is positive.\n",
    "- The growth_cpi's coefficient went from a -22,99 to a -10,65. The impact of annual inflation, whilst higher in magnitude, hasn't changed in terms of signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
